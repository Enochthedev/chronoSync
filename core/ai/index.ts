import { askOllama } from './ollama.service.js';
import { memoryStore } from './memory.store.js';
import { learnFrom } from './trainer.js';
import { analyzeText } from '../nlp/index.js'; // ğŸ§  NLP module

export async function askWithMemory(prompt: string, userId: string, isPrivate = false): Promise<string> {
  const namespace = isPrivate ? `private:${userId}` : 'shared';

  // ğŸ§  Run NLP
  const { intent, entities } = analyzeText(prompt);
  console.log('ğŸ§  Detected Intent:', intent);

  // ğŸ‘¤ Store name dynamically if found
  if (entities.name) {
    await learnFrom({
      content: `The user's name is ${entities.name}.`,
      query: prompt,
      source: 'user-identity',
      namespace,
    });
  }

  // ğŸ§  Load memory
  const memories = await memoryStore.search(prompt, namespace);
  const nameMemory = memories.find(m =>
    /user's name is|you can call me|my name is/i.test(m.content)
  );

  const nameContext = nameMemory
    ? `The user's name is: ${nameMemory.content}\n\n`
    : '';

  const context = nameContext + memories.map(m => m.content).join('\n\n');


  // ğŸ§‘â€ğŸš€ Chrono Personality
  const personality = `
You are Chrono â€” a clever, nerdy assistant who speaks naturally like a real person. 
Avoid roleplaying conversations (no "User:" or "Chrono:"). 
Be smart, witty, and mildly sarcastic when it fits â€” but never overdo it.
Only answer whatâ€™s asked. Donâ€™t create imagined dialogue.
Speak casually, like a high-IQ friend who reads too many sci-fi comics.
`;

  const finalPrompt = context
    ? `${personality}\n\nBased on the context below, respond to the user's message:\n\n${context}\n\nUser: ${prompt}`
    : `${personality}\n\nUser: ${prompt}`;

  console.log('ğŸ§  Final Prompt Sent to Ollama:\n', finalPrompt);

  const response = await askOllama(finalPrompt);
  console.log('ğŸ§  Ollama Response:', response);

  if (!response || typeof response !== 'string' || response.trim() === '') {
    console.warn('âŒ No response from Ollama.');
    return "ğŸ¤– Sorry, I didn't get a response from my AI core. Try again!";
  }

  // ğŸ’¾ Learn from response
  await learnFrom({
    query: prompt,
    content: response,
    source: 'conversation',
    namespace,
  });

  return response;
}